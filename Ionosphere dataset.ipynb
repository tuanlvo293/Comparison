{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Y-AWFnkD5z",
        "outputId": "a3648e14-ff3f-4212-bd14-2fdfdf4ca3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.4)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.4.post1)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=1ee2d4cfbd1cd859178adfce2e970cc456a2559b2af11ca7994ca91a32776cc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11329 sha256=eff7d5542a58c41f49d87371275c343b84a5adf6c6c929554b7df0b2405bd817\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install fancyimpute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMCK7YIkS8C",
        "outputId": "203aee4d-3570-407e-c8e6-9115e4c88559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting DistributedMissForest\n",
            "  Downloading DistributedMissForest-1.4.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (3.2.0)\n",
            "Building wheels for collected packages: DistributedMissForest\n",
            "  Building wheel for DistributedMissForest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DistributedMissForest: filename=DistributedMissForest-1.4-py3-none-any.whl size=17469 sha256=a9775d5e77a3e3f80e255dce24a48d1cb201d217220268b87af1f53458fe2ce8\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/93/ad/606370d3635fc2b977fafeeccd59929f886b09f19d4386e0ac\n",
            "Successfully built DistributedMissForest\n",
            "Installing collected packages: DistributedMissForest\n",
            "Successfully installed DistributedMissForest-1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install DistributedMissForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOaKOAakfaT",
        "outputId": "290f38bc-0658-4784-fd36-6270d38cda8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting missingpy\n",
            "  Downloading missingpy-0.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m489.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install missingpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xKJUhIfkrTJ",
        "outputId": "889ec8f9-dbc8-4f07-b51d-668203914424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting MissForest\n",
            "  Downloading MissForest-2.4.2-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: MissForest\n",
            "Successfully installed MissForest-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install MissForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEdO9dJPION8"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.neighbors._base\n",
        "import sys\n",
        "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy import stats\n",
        "from fancyimpute import SoftImpute\n",
        "from missforest.missforest import MissForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.linalg import norm, inv, det"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUB2K6WzRuNv"
      },
      "outputs": [],
      "source": [
        "def diag_term(i, X, y, G):\n",
        "    arr0 = X[:, i]\n",
        "    arr = arr0[~np.isnan(arr0)]\n",
        "    y_arr = y[~np.isnan(arr0)]\n",
        "\n",
        "    _, counts = np.unique(y_arr, return_counts = True)\n",
        "    ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "    return sum([(ind[g] - ind[g - 1]) * np.var(arr[y_arr == g - 1]) for\n",
        "                g in range(1, G + 1)]) / len(y_arr)\n",
        "\n",
        "\n",
        "def dper(X, y, G):\n",
        "    '''\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G\n",
        "    '''\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "    n, p = X.shape[0], X.shape[1]\n",
        "\n",
        "    mus = np.array(\n",
        "        [np.nanmean(X[y == g, :], axis = 0) for g in range(G)]).T  # so that each column is the mean of a class\n",
        "\n",
        "    S = np.diag([diag_term(i, X, y, G) for i in range(p)])\n",
        "\n",
        "    for i in range(p):\n",
        "        for j in range(i):\n",
        "            mat = X[:, [i, j]]\n",
        "\n",
        "            # drop rows with NA\n",
        "            idx = ~np.isnan(mat).any(axis = 1)\n",
        "            mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "            _, counts = np.unique(y_arr, return_counts = True)\n",
        "            ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "            m_g = counts\n",
        "\n",
        "            A = len(y_arr)\n",
        "\n",
        "            scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "            s11 = sum(map(q, range(G)))\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "            s22 = sum(map(q, range(G)))\n",
        "            d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "            s12 = sum(map(d, range(G)))\n",
        "\n",
        "            start_solve = time.time()\n",
        "            B = S[i, i] * S[j, j] * A - s22 * S[i, i] - s11 * S[j, j]\n",
        "            coefficient = [-A, s12, B, s12 * S[i, i] * S[j, j]]\n",
        "            r = np.roots(coefficient)\n",
        "\n",
        "            r = r[abs(np.imag(r)) < epsilon]\n",
        "            r = np.real(r)\n",
        "            r[abs(r) < epsilon] = 0\n",
        "\n",
        "            if len(r) > 1:\n",
        "                condi_var = S[j, j] - r ** 2 / S[i, i]\n",
        "                eta = -A * np.log(condi_var) - (S[j, j] - 2 * r / S[i, i] * s12 +\n",
        "                                                r ** 2 / S[i, i] ** 2 * s11) / condi_var\n",
        "                # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "                #  therefore, we drop NA elements of eta\n",
        "                r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "            if len(r) > 1:\n",
        "                w = [m_g[g - 1] * np.cov(mat[ind[g - 1]:ind[g], ], rowvar = False) for\n",
        "                     g in range(1, G + 1)]\n",
        "                w = np.sum(w, axis = 0)\n",
        "                r = r[np.abs(r - w[0, 1]).argmin()]  # choose r that is w[0,1]\n",
        "\n",
        "            S[i, j] = S[j, i] = r\n",
        "    return [mus, S]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbFXSh5VR_Ab"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "\n",
        "def generate_nan(X, non_missing , missing_rate):\n",
        "    X_copy=np.copy(X)\n",
        "\n",
        "    X_non_missing_col = X_copy[:, non_missing]\n",
        "    X1_missing = X_copy[:, [i for i in range(X.shape[1]) if i not in non_missing]]\n",
        "\n",
        "    X_non_missing_row = X1_missing[non_missing]\n",
        "    X_missing = X1_missing[len(non_missing):(X.shape[0]+1)]\n",
        "\n",
        "    XmShape = X_missing.shape\n",
        "    na_id = np.random.randint(0, X_missing.size, round(missing_rate * X_missing.size))\n",
        "    X_nan = X_missing.flatten()\n",
        "    X_nan[na_id] = np.nan\n",
        "    X_nan = X_nan.reshape(XmShape)\n",
        "\n",
        "    X1_nan = np.vstack((X_non_missing_row, X_nan))\n",
        "    X_nan = np.hstack((X_non_missing_col, X1_nan))\n",
        "    return X_nan\n",
        "\n",
        "def PHF(Xm, y, G):\n",
        "    p = Xm.shape[1]\n",
        "    non_missing_id = np.where(np.sum(np.isnan(Xm), axis = 0) == 0)\n",
        "    q = max(non_missing_id)[-1] + 1\n",
        "    # initialize the parameter with 0s\n",
        "    S = np.zeros((p, p))\n",
        "    # estimating the parameter for the fully observed features\n",
        "    mu = np.array([np.nanmean(Xm[y == g, :], axis = 0) for g in range(G)]).T  # the mean is stored column\n",
        "    S[:q, :q] = sum([sum(y == g) * np.cov(Xm[y == g, :q], rowvar = False, ddof = 0) for g in range(G)]) / len(y)\n",
        "    # estimating the parameter in step 2 of the algorithm:\n",
        "    for j in range(q, p):\n",
        "        id = ~np.isnan(Xm[:, j])\n",
        "        Xfj = Xm[id, :][:, np.hstack((range(q), j))]\n",
        "        yfj = y[id]\n",
        "        covm = sum([sum(yfj == g) * np.cov(Xfj[yfj == g, :], rowvar = False, ddof = 0) for g in range(G)]) / len(yfj)\n",
        "        Q = covm[-1, range(q)]  # row vector\n",
        "        P = np.matmul(Q, np.linalg.inv(covm[:q, :q]))\n",
        "        S[j, range(q)] = np.matmul(P, S[:q, :q])\n",
        "\n",
        "        Xj, yj = Xm[id, j], y[id]\n",
        "        cal_S = lambda g: np.dot(Xj[yj == g] - mu[j, g], Xj[yj == g] - mu[j, g])\n",
        "        S[j, j] = sum(map(cal_S, range(G)))/len(yj)\n",
        "\n",
        "        S[j, range(q, j)] = np.array([dper_sigij(Xm, y, G, mu, i, j, S[i, i], S[j, j]) for i in range(q, j)]).flatten()\n",
        "        S[:, j] = S[j, :].T\n",
        "    return mu, S\n",
        "\n",
        "\n",
        "def dper_sigij(X, y, G, mus, i, j, sigii, sigjj):\n",
        "    \"\"\"\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    i, j: index of the column\n",
        "    sigii: sigma_ii\n",
        "    sigjj: sigma_jj\n",
        "    \"\"\"\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "\n",
        "    mat = X[:, [i, j]]\n",
        "\n",
        "    # drop rows with NA\n",
        "    idx = ~np.isnan(mat).any(axis = 1)\n",
        "    mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "    A = len(y_arr)\n",
        "    scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "    s11 = sum(map(q, range(G)))\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "    s22 = sum(map(q, range(G)))\n",
        "    d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "    s12 = sum(map(d, range(G)))\n",
        "    B = sigii * sigjj * A - s22 * sigii - s11 * sigjj\n",
        "    coefficient = [-A, s12, B, s12 * sigii * sigjj]\n",
        "    r = np.roots(coefficient)\n",
        "\n",
        "    r = r[abs(np.imag(r)) < epsilon]\n",
        "    r = np.real(r)\n",
        "    r[abs(r) < epsilon] = 0\n",
        "\n",
        "    if len(r) > 1:\n",
        "        condi_var = sigjj - r ** 2 / sigii\n",
        "        # print('condi_var',condi_var)\n",
        "        eta = -A * np.log(condi_var) - (sigjj - 2 * r / sigii * s12 +\n",
        "                                        r ** 2 / sigii ** 2 * s11) / condi_var\n",
        "        # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "        #  therefore, we drop NA elements of eta\n",
        "        r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "    if len(r) > 1:\n",
        "        r = r[np.abs(r - s12 / A).argmin()]  # select r that is closet to w[0,1]\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def PHF1Cl(Xm):\n",
        "  p = Xm.shape[1]\n",
        "  non_missing_id = np.where(np.sum(np.isnan(Xm), axis=0)==0)\n",
        "  q = max(non_missing_id)[-1] + 1\n",
        "  # initialize the parameter with 0s\n",
        "  mu = np.zeros((p, 1))\n",
        "  S = np.zeros((p,p))\n",
        "  # estimating the parameter for the fully observed features\n",
        "  mu[:q,:] = np.mean(Xm[:,:q], axis = 0).reshape((-1,1)) # the mean is stored column\n",
        "  S[:q,:q] =   np.cov(Xm[:, :q], rowvar = False, ddof = 0)\n",
        "  # estimating the parameter in step 2 of the algorithm:\n",
        "  for j in range(q,p):\n",
        "    id = ~np.isnan(Xm[:,j])\n",
        "    Xfj = Xm[id,:][:,np.hstack((range(q),j))]\n",
        "    covm = np.cov(Xfj, rowvar = False, ddof = 0)\n",
        "    Q = covm[-1,range(q)] #row vector\n",
        "    P = np.matmul(Q, np.linalg.inv(covm[:q,:q]))\n",
        "    S[j,range(q)]  = np.matmul(P, S[:q,:q])\n",
        "\n",
        "    idj = ~np.isnan(Xm[:,j])\n",
        "    Xj = Xm[idj,j]\n",
        "    mu[j,:] =  np.nanmean(Xm[:,j], axis = 0)\n",
        "    S[j,j] = sum((Xj - mu[j])**2) /len(Xj)\n",
        "\n",
        "    S[j, range(q,j)] = np.array([dper_sigij1Cl(Xm, mu, i,j, S[i,i], S[j,j]) for i in range(q,j)]).flatten()\n",
        "    S[:,j] = S[j, :].T\n",
        "  return mu, S\n",
        "\n",
        "def dper_sigij1Cl(X, mus, i,j, sigii, sigjj):\n",
        "        '''\n",
        "        X: input, should be a numpy array\n",
        "        y: label\n",
        "        G: number of classes\n",
        "        i, j: index of the column\n",
        "        sigii: sigma_ii\n",
        "        sigjj: sigma_jj\n",
        "        '''\n",
        "        epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "        n,p = X.shape[0], X.shape[1]\n",
        "\n",
        "        mat = X[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat = mat[idx]\n",
        "\n",
        "        A = len(mat)\n",
        "        scaled_mat = mat-mus[[i,j]].T\n",
        "        scaled_mat = np.vstack(scaled_mat)\n",
        "        s11 = sum(scaled_mat[:,0]**2)\n",
        "        s22 = sum(scaled_mat[:,1]**2)\n",
        "        s12 = sum(scaled_mat[:,0]*scaled_mat[:,1])\n",
        "\n",
        "        B = sigii*sigjj*A - s22 * sigii - s11 * sigjj\n",
        "        coefficient = [-A, s12, B, s12*sigii*sigjj]\n",
        "        r = np.roots(coefficient)\n",
        "\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        "\n",
        "        if len(r)>1:\n",
        "          condi_var = sigjj - r**2/sigii\n",
        "          # print('condi_var',condi_var)\n",
        "          eta = -A*np.log(condi_var)-(sigjj-2*r/sigii*s12 +\n",
        "                                      r**2/sigii**2*s11)/condi_var\n",
        "          # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "          #  therefore, we drop NA elements of eta\n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1:\n",
        "            r = r[np.abs(r-s12/A).argmin()] # select r that is closet to w[0,1]\n",
        "\n",
        "        return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnXPL5TYjN1Q"
      },
      "outputs": [],
      "source": [
        "def l2err_inv(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return (norm(inv(Strue)-inv(S))/(p*p))\n",
        "\n",
        "def l2err(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return (norm((Strue)-(S)) / (p*p))\n",
        "\n",
        "def normalize_data(X):\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X)\n",
        "  return scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3jJgOfdqkH"
      },
      "outputs": [],
      "source": [
        "def experiment(X,y, n, missing_rate):\n",
        "    G = len(np.unique(y))\n",
        "    S0=np.cov(X.T)\n",
        "    #print(S0.shape)\n",
        "    err = []\n",
        "    i_err=[]\n",
        "    for i in range(n):\n",
        "        mu_0=np.array([np.mean(X[y==g,:])  for g in np.unique(y) ]).T\n",
        "        Xm0 = generate_nan(X, [0,1], missing_rate)\n",
        "        Xm=Xm0\n",
        "        muPhf, SPhf = PHF(Xm, y, G)\n",
        "\n",
        "        muDper, SDper = dper(Xm, y, G)\n",
        "\n",
        "        XMice= IterativeImputer(max_iter=100).fit(Xm).transform(Xm)\n",
        "        SMice =  sum([sum(y==g)*np.cov(XMice[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        Xm_copy= pd.DataFrame.from_records(Xm)\n",
        "        Missf= MissForest()\n",
        "        XMissf_df = Missf.fit_transform(Xm_copy)\n",
        "        XMissf= XMissf_df.to_numpy()\n",
        "        SMissf =  sum([sum(y==g)*np.cov(XMissf[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        XSoft =  SoftImpute(max_iters = 100, verbose = False).fit_transform(Xm)\n",
        "        SSoft =  sum([sum(y==g)*np.cov(XSoft[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "#       Xxgb = XGBImputer().fit_transform(Xm)\n",
        "#       Sxgb = sum([sum(y==g)*np.cov(Xxgb[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        i_err.append(np.array([l2err_inv(S0, SPhf), l2err_inv(S0, SDper),\n",
        "                             l2err_inv(S0, SMice), l2err_inv(S0, SMissf),\n",
        "                             l2err_inv(S0, SSoft)]))\n",
        "\n",
        "        err.append(np.array([l2err(S0, SPhf), l2err(S0, SDper),\n",
        "                             l2err(S0, SMice), l2err(S0, SMissf),\n",
        "                             l2err(S0, SSoft)]))\n",
        "    return i_err, err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcRZu-ydrl44"
      },
      "source": [
        "#Ionosphere\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXc4k-LBrqVl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data',\n",
        "                  sep = \",\", header = None)\n",
        "data.head()\n",
        "data = pd.DataFrame.to_numpy(data)\n",
        "X, y = data[:,:34].astype(np.float64), data[:,34]\n",
        "le2 = LabelEncoder()\n",
        "y = le2.fit_transform(y)\n",
        "G = len(np.unique(y))\n",
        "X = np.delete(X,[0,1], axis = 1)\n",
        "for g in range(G):\n",
        "  print(sum(y==g))\n",
        "X.shape\n",
        "X = normalize_data(X)\n",
        "S = np.cov(X, rowvar = False)\n",
        "print(norm(S))\n",
        "print(norm(inv(S)))\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKqWgFlYr_6G",
        "outputId": "57bbf8e9-0b81-4b02-83e5-c45e3468f954"
      },
      "outputs": [],
      "source": [
        "num = 10\n",
        "e_inv20,e20 = experiment(X,y,num, missing_rate=.2)\n",
        "e_inv40,e40 = experiment(X,y,num, missing_rate=.4)\n",
        "e_inv60,e60 = experiment(X,y,num, missing_rate=.6)\n",
        "e_inv80,e80 = experiment(X,y,num, missing_rate=.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY6m1kqYr9MO",
        "outputId": "cc6263e8-156f-488b-b012-769bf0e9fec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.002, 0.002, 0.002, 0.004, 0.002],\n",
              "       [0.003, 0.003, 0.003, 0.006, 0.003],\n",
              "       [0.003, 0.003, 0.003, 0.007, 0.004],\n",
              "       [0.004, 0.004, 0.004, 0.008, 0.005]])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e20, axis = 0), np.mean(e40, axis = 0),\n",
        "          np.mean(e60, axis = 0),np.mean(e80, axis = 0))).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbjt2Wsdr9MP",
        "outputId": "3e0acc5e-e4d2-480b-fefe-814cbeca90aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e20, axis = 0), np.std(e40, axis = 0),\n",
        "          np.std(e60, axis = 0),np.std(e80, axis = 0))).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTuyOrFmr9MP",
        "outputId": "6a078562-412f-4d50-cb48-a524efae5540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inv err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[5.47383166e+00, 3.64511117e-01, 1.97447779e+07, 1.26140747e-02,\n",
              "        1.79638366e-02],\n",
              "       [1.20651005e-01, 1.75555407e-01, 1.72841277e+12, 1.49283892e-02,\n",
              "        3.88629677e-02],\n",
              "       [4.82442403e-01, 1.34399095e+00, 1.55684404e+12, 1.54654331e-02,\n",
              "        9.16412456e-02],\n",
              "       [1.80988438e-01, 3.58996952e-01, 4.55901423e+12, 1.54424993e-02,\n",
              "        2.22570004e-01]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('inv err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e_inv20, axis = 0), np.mean(e_inv40, axis = 0),\n",
        "          np.mean(e_inv60, axis = 0),np.mean(e_inv80, axis = 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hYOlfeFr9MP",
        "outputId": "c030715f-c7ac-4753-dad9-a629a9219025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inv std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.58410000e+01, 5.44000000e-01, 5.78638454e+07, 1.00000000e-03,\n",
              "        2.00000000e-03],\n",
              "       [7.90000000e-02, 1.42000000e-01, 4.46249971e+12, 0.00000000e+00,\n",
              "        5.00000000e-03],\n",
              "       [7.15000000e-01, 3.20700000e+00, 2.55247781e+12, 0.00000000e+00,\n",
              "        1.70000000e-02],\n",
              "       [1.77000000e-01, 7.76000000e-01, 8.43368178e+12, 0.00000000e+00,\n",
              "        6.20000000e-02]])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('inv std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e_inv20, axis = 0), np.std(e_inv40, axis = 0),\n",
        "          np.std(e_inv60, axis = 0),np.std(e_inv80,axis = 0))).round(3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "01Q1wGI3uIdg",
        "7XnuorFPQfuU",
        "lOGrMzuBKHTT",
        "CuD6fWFzlYrg"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
