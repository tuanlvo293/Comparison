{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fancyimpute"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Y-AWFnkD5z",
        "outputId": "428cab2f-8f12-4316-ec06-71c0af9a8def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fancyimpute in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: knnimpute>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (0.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.3)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.4)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.1.3)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DistributedMissForest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMCK7YIkS8C",
        "outputId": "70da05d7-addf-41e6-ee56-8e08c4bbb681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: DistributedMissForest in /usr/local/lib/python3.10/dist-packages (1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install missingpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOaKOAakfaT",
        "outputId": "c305238d-00c3-4ab1-c44c-73782fb20032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: missingpy in /usr/local/lib/python3.10/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install MissForest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xKJUhIfkrTJ",
        "outputId": "50027948-6377-435f-e0bf-65b24cb11dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: MissForest in /usr/local/lib/python3.10/dist-packages (2.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEdO9dJPION8"
      },
      "outputs": [],
      "source": [
        "import sklearn.neighbors._base\n",
        "import sys\n",
        "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
        "# !pip install impyute\n",
        "# !pip install fancyimpute\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "# import impyute as impy\n",
        "from fancyimpute import SoftImpute#, MatrixFactorization\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "# from missingpy\n",
        "from missforest.missforest import MissForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from functions.phf import *\n",
        "# from functions.da import *\n",
        "# from functions.dper import *\n",
        "from numpy.linalg import norm, inv\n",
        "# from xgbimputer import XGBImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diag_term(i, X, y, G):\n",
        "    arr0 = X[:, i]\n",
        "    arr = arr0[~np.isnan(arr0)]\n",
        "    y_arr = y[~np.isnan(arr0)]\n",
        "\n",
        "    _, counts = np.unique(y_arr, return_counts = True)\n",
        "    ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "    return sum([(ind[g] - ind[g - 1]) * np.var(arr[y_arr == g - 1]) for\n",
        "                g in range(1, G + 1)]) / len(y_arr)\n",
        "\n",
        "\n",
        "def dper(X, y, G):\n",
        "    '''\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G\n",
        "    '''\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "    n, p = X.shape[0], X.shape[1]\n",
        "\n",
        "    mus = np.array(\n",
        "        [np.nanmean(X[y == g, :], axis = 0) for g in range(G)]).T  # so that each column is the mean of a class\n",
        "\n",
        "    S = np.diag([diag_term(i, X, y, G) for i in range(p)])\n",
        "\n",
        "    for i in range(p):\n",
        "        for j in range(i):\n",
        "            mat = X[:, [i, j]]\n",
        "\n",
        "            # drop rows with NA\n",
        "            idx = ~np.isnan(mat).any(axis = 1)\n",
        "            mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "            _, counts = np.unique(y_arr, return_counts = True)\n",
        "            ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "            m_g = counts\n",
        "\n",
        "            A = len(y_arr)\n",
        "\n",
        "            scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "            s11 = sum(map(q, range(G)))\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "            s22 = sum(map(q, range(G)))\n",
        "            d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "            s12 = sum(map(d, range(G)))\n",
        "\n",
        "            start_solve = time.time()\n",
        "            B = S[i, i] * S[j, j] * A - s22 * S[i, i] - s11 * S[j, j]\n",
        "            coefficient = [-A, s12, B, s12 * S[i, i] * S[j, j]]\n",
        "            r = np.roots(coefficient)\n",
        "\n",
        "            r = r[abs(np.imag(r)) < epsilon]\n",
        "            r = np.real(r)\n",
        "            r[abs(r) < epsilon] = 0\n",
        "\n",
        "            if len(r) > 1:\n",
        "                condi_var = S[j, j] - r ** 2 / S[i, i]\n",
        "                eta = -A * np.log(condi_var) - (S[j, j] - 2 * r / S[i, i] * s12 +\n",
        "                                                r ** 2 / S[i, i] ** 2 * s11) / condi_var\n",
        "                # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "                #  therefore, we drop NA elements of eta\n",
        "                r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "            if len(r) > 1:\n",
        "                w = [m_g[g - 1] * np.cov(mat[ind[g - 1]:ind[g], ], rowvar = False) for\n",
        "                     g in range(1, G + 1)]\n",
        "                w = np.sum(w, axis = 0)\n",
        "                r = r[np.abs(r - w[0, 1]).argmin()]  # choose r that is w[0,1]\n",
        "\n",
        "            S[i, j] = S[j, i] = r\n",
        "    return [mus, S]"
      ],
      "metadata": {
        "id": "uUB2K6WzRuNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "\n",
        "def generate_nan(X, non_missing , missing_rate):\n",
        "    X_copy=np.copy(X)\n",
        "\n",
        "    X_non_missing_col = X_copy[:, non_missing]\n",
        "    X1_missing = X_copy[:, [i for i in range(X.shape[1]) if i not in non_missing]]\n",
        "\n",
        "    X_non_missing_row = X1_missing[non_missing]\n",
        "    X_missing = X1_missing[len(non_missing):(X.shape[0]+1)]\n",
        "\n",
        "    XmShape = X_missing.shape\n",
        "    na_id = np.random.randint(0, X_missing.size, round(missing_rate * X_missing.size))\n",
        "    X_nan = X_missing.flatten()\n",
        "    X_nan[na_id] = np.nan\n",
        "    X_nan = X_nan.reshape(XmShape)\n",
        "\n",
        "    X1_nan = np.vstack((X_non_missing_row, X_nan))\n",
        "    X_nan = np.hstack((X_non_missing_col, X1_nan))\n",
        "    return X_nan\n",
        "\n",
        "def PHF(Xm, y, G):\n",
        "    p = Xm.shape[1]\n",
        "    non_missing_id = np.where(np.sum(np.isnan(Xm), axis = 0) == 0)\n",
        "    q = max(non_missing_id)[-1] + 1\n",
        "    # initialize the parameter with 0s\n",
        "    S = np.zeros((p, p))\n",
        "    # estimating the parameter for the fully observed features\n",
        "    mu = np.array([np.nanmean(Xm[y == g, :], axis = 0) for g in range(G)]).T  # the mean is stored column\n",
        "    S[:q, :q] = sum([sum(y == g) * np.cov(Xm[y == g, :q], rowvar = False, ddof = 0) for g in range(G)]) / len(y)\n",
        "    # estimating the parameter in step 2 of the algorithm:\n",
        "    for j in range(q, p):\n",
        "        id = ~np.isnan(Xm[:, j])\n",
        "        Xfj = Xm[id, :][:, np.hstack((range(q), j))]\n",
        "        yfj = y[id]\n",
        "        covm = sum([sum(yfj == g) * np.cov(Xfj[yfj == g, :], rowvar = False, ddof = 0) for g in range(G)]) / len(yfj)\n",
        "        Q = covm[-1, range(q)]  # row vector\n",
        "        P = np.matmul(Q, np.linalg.inv(covm[:q, :q]))\n",
        "        S[j, range(q)] = np.matmul(P, S[:q, :q])\n",
        "\n",
        "        Xj, yj = Xm[id, j], y[id]\n",
        "        cal_S = lambda g: np.dot(Xj[yj == g] - mu[j, g], Xj[yj == g] - mu[j, g])\n",
        "        S[j, j] = sum(map(cal_S, range(G)))/len(yj)\n",
        "\n",
        "        S[j, range(q, j)] = np.array([dper_sigij(Xm, y, G, mu, i, j, S[i, i], S[j, j]) for i in range(q, j)]).flatten()\n",
        "        S[:, j] = S[j, :].T\n",
        "    return mu, S\n",
        "\n",
        "\n",
        "def dper_sigij(X, y, G, mus, i, j, sigii, sigjj):\n",
        "    \"\"\"\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    i, j: index of the column\n",
        "    sigii: sigma_ii\n",
        "    sigjj: sigma_jj\n",
        "    \"\"\"\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "\n",
        "    mat = X[:, [i, j]]\n",
        "\n",
        "    # drop rows with NA\n",
        "    idx = ~np.isnan(mat).any(axis = 1)\n",
        "    mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "    A = len(y_arr)\n",
        "    scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "    s11 = sum(map(q, range(G)))\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "    s22 = sum(map(q, range(G)))\n",
        "    d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "    s12 = sum(map(d, range(G)))\n",
        "    B = sigii * sigjj * A - s22 * sigii - s11 * sigjj\n",
        "    coefficient = [-A, s12, B, s12 * sigii * sigjj]\n",
        "    r = np.roots(coefficient)\n",
        "\n",
        "    r = r[abs(np.imag(r)) < epsilon]\n",
        "    r = np.real(r)\n",
        "    r[abs(r) < epsilon] = 0\n",
        "\n",
        "    if len(r) > 1:\n",
        "        condi_var = sigjj - r ** 2 / sigii\n",
        "        # print('condi_var',condi_var)\n",
        "        eta = -A * np.log(condi_var) - (sigjj - 2 * r / sigii * s12 +\n",
        "                                        r ** 2 / sigii ** 2 * s11) / condi_var\n",
        "        # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "        #  therefore, we drop NA elements of eta\n",
        "        r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "    if len(r) > 1:\n",
        "        r = r[np.abs(r - s12 / A).argmin()]  # select r that is closet to w[0,1]\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def PHF1Cl(Xm):\n",
        "  p = Xm.shape[1]\n",
        "  non_missing_id = np.where(np.sum(np.isnan(Xm), axis=0)==0)\n",
        "  q = max(non_missing_id)[-1] + 1\n",
        "  # initialize the parameter with 0s\n",
        "  mu = np.zeros((p, 1))\n",
        "  S = np.zeros((p,p))\n",
        "  # estimating the parameter for the fully observed features\n",
        "  mu[:q,:] = np.mean(Xm[:,:q], axis = 0).reshape((-1,1)) # the mean is stored column\n",
        "  S[:q,:q] =   np.cov(Xm[:, :q], rowvar = False, ddof = 0)\n",
        "  # estimating the parameter in step 2 of the algorithm:\n",
        "  for j in range(q,p):\n",
        "    id = ~np.isnan(Xm[:,j])\n",
        "    Xfj = Xm[id,:][:,np.hstack((range(q),j))]\n",
        "    covm = np.cov(Xfj, rowvar = False, ddof = 0)\n",
        "    Q = covm[-1,range(q)] #row vector\n",
        "    P = np.matmul(Q, np.linalg.inv(covm[:q,:q]))\n",
        "    S[j,range(q)]  = np.matmul(P, S[:q,:q])\n",
        "\n",
        "    idj = ~np.isnan(Xm[:,j])\n",
        "    Xj = Xm[idj,j]\n",
        "    mu[j,:] =  np.nanmean(Xm[:,j], axis = 0)\n",
        "    S[j,j] = sum((Xj - mu[j])**2) /len(Xj)\n",
        "\n",
        "    S[j, range(q,j)] = np.array([dper_sigij1Cl(Xm, mu, i,j, S[i,i], S[j,j]) for i in range(q,j)]).flatten()\n",
        "    S[:,j] = S[j, :].T\n",
        "  return mu, S\n",
        "\n",
        "def dper_sigij1Cl(X, mus, i,j, sigii, sigjj):\n",
        "        '''\n",
        "        X: input, should be a numpy array\n",
        "        y: label\n",
        "        G: number of classes\n",
        "        i, j: index of the column\n",
        "        sigii: sigma_ii\n",
        "        sigjj: sigma_jj\n",
        "        '''\n",
        "        epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "        n,p = X.shape[0], X.shape[1]\n",
        "\n",
        "        mat = X[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat = mat[idx]\n",
        "\n",
        "        A = len(mat)\n",
        "        scaled_mat = mat-mus[[i,j]].T\n",
        "        scaled_mat = np.vstack(scaled_mat)\n",
        "        s11 = sum(scaled_mat[:,0]**2)\n",
        "        s22 = sum(scaled_mat[:,1]**2)\n",
        "        s12 = sum(scaled_mat[:,0]*scaled_mat[:,1])\n",
        "\n",
        "        B = sigii*sigjj*A - s22 * sigii - s11 * sigjj\n",
        "        coefficient = [-A, s12, B, s12*sigii*sigjj]\n",
        "        r = np.roots(coefficient)\n",
        "\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        "\n",
        "        if len(r)>1:\n",
        "          condi_var = sigjj - r**2/sigii\n",
        "          # print('condi_var',condi_var)\n",
        "          eta = -A*np.log(condi_var)-(sigjj-2*r/sigii*s12 +\n",
        "                                      r**2/sigii**2*s11)/condi_var\n",
        "          # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "          #  therefore, we drop NA elements of eta\n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1:\n",
        "            r = r[np.abs(r-s12/A).argmin()] # select r that is closet to w[0,1]\n",
        "\n",
        "        return r"
      ],
      "metadata": {
        "id": "TbFXSh5VR_Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnXPL5TYjN1Q"
      },
      "outputs": [],
      "source": [
        "def l2err_inv(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return norm(inv(Strue)-inv(S))/(p*p)\n",
        "\n",
        "def l2err(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return norm((Strue)-(S)) / (p*p)\n",
        "\n",
        "def normalize_data(X):\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X)\n",
        "  return scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3jJgOfdqkH"
      },
      "outputs": [],
      "source": [
        "def experiment(X,y, n, missing_rate):\n",
        "    G = len(np.unique(y))\n",
        "    S0=np.cov(X.T)\n",
        "    #print(S0.shape)\n",
        "    err = []\n",
        "    i_err=[]\n",
        "    for i in range(n):\n",
        "        mu_0=np.array([np.mean(X[y==g,:])  for g in np.unique(y) ]).T\n",
        "        Xm0 = generate_nan(X, [0,1], missing_rate)\n",
        "        Xm=Xm0\n",
        "        muPhf, SPhf = PHF(Xm, y, G)\n",
        "\n",
        "        muDper, SDper = dper(Xm, y, G)\n",
        "\n",
        "        XMice= IterativeImputer(max_iter=100).fit(Xm).transform(Xm)\n",
        "        SMice =  sum([sum(y==g)*np.cov(XMice[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        Xm_copy= pd.DataFrame.from_records(Xm)\n",
        "        Missf= MissForest()\n",
        "        XMissf_df = Missf.fit_transform(Xm_copy)\n",
        "        XMissf= XMissf_df.to_numpy()\n",
        "        SMissf =  sum([sum(y==g)*np.cov(XMissf[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        XSoft =  SoftImpute(max_iters = 100, verbose = False).fit_transform(Xm)\n",
        "        SSoft =  sum([sum(y==g)*np.cov(XSoft[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "#       Xxgb = XGBImputer().fit_transform(Xm)\n",
        "#       Sxgb = sum([sum(y==g)*np.cov(Xxgb[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        i_err.append(np.array([l2err_inv(S0, SPhf), l2err_inv(S0, SDper),\n",
        "                             l2err_inv(S0, SMice), l2err_inv(S0, SMissf),\n",
        "                             l2err_inv(S0, SSoft)]))\n",
        "\n",
        "        err.append(np.array([l2err(S0, SPhf), l2err(S0, SDper),\n",
        "                             l2err(S0, SMice), l2err(S0, SMissf),\n",
        "                             l2err(S0, SSoft)]))\n",
        "    return i_err, err"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment on dataset 4: Liver"
      ],
      "metadata": {
        "id": "2_Cfc2hTIo5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/liver-disorders/bupa.data',\n",
        "                  sep = \",\", header = None)\n",
        "data = data.to_numpy()\n",
        "X,y = data[:, [x for x in range(data.shape[1]) if x != 6]].astype(np.float32),data[:,-1]\n",
        "G = len(np.unique(y))\n",
        "le2 = LabelEncoder()\n",
        "y = le2.fit_transform(y)\n",
        "for g in range(G):\n",
        "  print(sum(y==g))\n",
        "print(X.shape)\n",
        "X = normalize_data(X)\n",
        "S = np.cov(X,rowvar = False)\n",
        "print(norm(S).round(3))\n",
        "print(norm(inv(S)).round(3))\n",
        "print(np.linalg.det(S).round(3))\n",
        "print(np.linalg.det(inv(S)).round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaizHWK8Iw_F",
        "outputId": "35be4b3d-f28a-40d9-c7ed-2b24a1876e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145\n",
            "200\n",
            "(345, 6)\n",
            "3.035\n",
            "4.837\n",
            "0.237\n",
            "4.211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 10\n",
        "e_inv20,e20 = experiment(X,y,num, missing_rate=.2)\n",
        "e_inv40,e40 = experiment(X,y,num, missing_rate=.4)\n",
        "e_inv60,e60 = experiment(X,y,num, missing_rate=.6)\n",
        "e_inv80,e80 = experiment(X,y,num, missing_rate=.8)"
      ],
      "metadata": {
        "id": "Mu6fe-LDJI4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e20, axis = 0), np.mean(e40, axis = 0),\n",
        "          np.mean(e60, axis = 0),np.mean(e80, axis = 0))).round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8EGjYELJVYI",
        "outputId": "db2c112c-079a-4609-93c3-005ea4fe920c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.007, 0.007, 0.009, 0.009, 0.012],\n",
              "       [0.01 , 0.01 , 0.015, 0.016, 0.023],\n",
              "       [0.014, 0.014, 0.019, 0.039, 0.031],\n",
              "       [0.019, 0.019, 0.023, 0.046, 0.037]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e20, axis = 0), np.std(e40, axis = 0),\n",
        "          np.std(e60, axis = 0),np.std(e80, axis = 0))).round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCjXJvBlJW_y",
        "outputId": "9820041b-0213-432d-f32f-6e93001d99d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.002, 0.002, 0.002, 0.003, 0.002],\n",
              "       [0.002, 0.002, 0.003, 0.003, 0.003],\n",
              "       [0.003, 0.003, 0.004, 0.004, 0.003],\n",
              "       [0.004, 0.004, 0.005, 0.003, 0.004]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('inv err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e_inv20, axis = 0), np.mean(e_inv40, axis = 0),\n",
        "          np.mean(e_inv60, axis = 0),np.mean(e_inv80, axis = 0))).round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOu91OuLJYmT",
        "outputId": "ad3dac37-5e3e-4693-b95f-9bd85cf1dd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inv err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.024, 0.024, 0.061, 0.026, 0.034],\n",
              "       [0.047, 0.047, 0.251, 0.047, 0.084],\n",
              "       [0.052, 0.052, 0.972, 0.051, 0.112],\n",
              "       [0.163, 0.162, 7.673, 0.061, 0.171]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('inv std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e_inv20, axis = 0), np.std(e_inv40, axis = 0),\n",
        "          np.std(e_inv60, axis = 0),np.std(e_inv80,axis = 0))).round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc0Z7sowJZ08",
        "outputId": "764ce300-1a28-4438-910b-00236e69c6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inv std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01 , 0.01 , 0.013, 0.007, 0.008],\n",
              "       [0.021, 0.021, 0.086, 0.015, 0.021],\n",
              "       [0.018, 0.017, 0.261, 0.012, 0.041],\n",
              "       [0.18 , 0.182, 6.092, 0.01 , 0.084]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "01Q1wGI3uIdg",
        "2_Cfc2hTIo5m"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}