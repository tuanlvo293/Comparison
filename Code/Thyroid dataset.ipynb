{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Q1wGI3uIdg"
      },
      "source": [
        "## libraries and function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52Y-AWFnkD5z",
        "outputId": "64dda17c-4eed-493e-cfd1-597470ec3565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.3)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.2.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.4.post1)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post0)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29880 sha256=8276619a6422ff0c60cc596b16b857a0ae096898bc9a4642a3f23763f94a4260\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11329 sha256=0e3131f8665d8d04d931249d35d5670b351064295e7287184cc1b4a179aa56e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install fancyimpute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMCK7YIkS8C",
        "outputId": "5a65792d-e9f7-4ef9-b48c-db241f849e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting DistributedMissForest\n",
            "  Downloading DistributedMissForest-1.4.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from DistributedMissForest) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DistributedMissForest) (3.2.0)\n",
            "Building wheels for collected packages: DistributedMissForest\n",
            "  Building wheel for DistributedMissForest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DistributedMissForest: filename=DistributedMissForest-1.4-py3-none-any.whl size=17469 sha256=412c535d9df0ac389a51d3c3088804303644832988720c6fbee1e1567ce6d204\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/93/ad/606370d3635fc2b977fafeeccd59929f886b09f19d4386e0ac\n",
            "Successfully built DistributedMissForest\n",
            "Installing collected packages: DistributedMissForest\n",
            "Successfully installed DistributedMissForest-1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install DistributedMissForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vOaKOAakfaT",
        "outputId": "d1a1817b-c5df-488d-8ec7-0f5ca90e7ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting missingpy\n",
            "  Downloading missingpy-0.2.0-py3-none-any.whl (49 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/49.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install missingpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xKJUhIfkrTJ",
        "outputId": "76fb70f9-5bb8-4acf-c5c3-0dc7943d6b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting MissForest\n",
            "  Downloading MissForest-2.2.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: MissForest\n",
            "Successfully installed MissForest-2.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install MissForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEdO9dJPION8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import sklearn.neighbors._base\n",
        "import sys\n",
        "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from fancyimpute import SoftImpute, KNN\n",
        "from missforest.missforest import MissForest\n",
        "from numpy.linalg import norm, inv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUB2K6WzRuNv"
      },
      "outputs": [],
      "source": [
        "def diag_term(i, X, y, G):\n",
        "    arr0 = X[:, i]\n",
        "    arr = arr0[~np.isnan(arr0)]\n",
        "    y_arr = y[~np.isnan(arr0)]\n",
        "\n",
        "    _, counts = np.unique(y_arr, return_counts = True)\n",
        "    ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "    return sum([(ind[g] - ind[g - 1]) * np.var(arr[y_arr == g - 1]) for\n",
        "                g in range(1, G + 1)]) / len(y_arr)\n",
        "\n",
        "\n",
        "def dper(X, y, G):\n",
        "    '''\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    output:\n",
        "    - mus: each row is a class mean\n",
        "    - S: common covariance matrix of class 1,2,..., G\n",
        "    '''\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "    n, p = X.shape[0], X.shape[1]\n",
        "\n",
        "    mus = np.array(\n",
        "        [np.nanmean(X[y == g, :], axis = 0) for g in range(G)]).T  # so that each column is the mean of a class\n",
        "\n",
        "    S = np.diag([diag_term(i, X, y, G) for i in range(p)])\n",
        "\n",
        "    for i in range(p):\n",
        "        for j in range(i):\n",
        "            mat = X[:, [i, j]]\n",
        "\n",
        "            # drop rows with NA\n",
        "            idx = ~np.isnan(mat).any(axis = 1)\n",
        "            mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "            _, counts = np.unique(y_arr, return_counts = True)\n",
        "            ind = np.insert(np.cumsum(counts), 0, 0)\n",
        "\n",
        "            m_g = counts\n",
        "\n",
        "            A = len(y_arr)\n",
        "\n",
        "            scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "            s11 = sum(map(q, range(G)))\n",
        "            q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "            s22 = sum(map(q, range(G)))\n",
        "            d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "            s12 = sum(map(d, range(G)))\n",
        "\n",
        "            start_solve = time.time()\n",
        "            B = S[i, i] * S[j, j] * A - s22 * S[i, i] - s11 * S[j, j]\n",
        "            coefficient = [-A, s12, B, s12 * S[i, i] * S[j, j]]\n",
        "            r = np.roots(coefficient)\n",
        "\n",
        "            r = r[abs(np.imag(r)) < epsilon]\n",
        "            r = np.real(r)\n",
        "            r[abs(r) < epsilon] = 0\n",
        "\n",
        "            if len(r) > 1:\n",
        "                condi_var = S[j, j] - r ** 2 / S[i, i]\n",
        "                eta = -A * np.log(condi_var) - (S[j, j] - 2 * r / S[i, i] * s12 +\n",
        "                                                r ** 2 / S[i, i] ** 2 * s11) / condi_var\n",
        "                # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "                #  therefore, we drop NA elements of eta\n",
        "                r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "            if len(r) > 1:\n",
        "                w = [m_g[g - 1] * np.cov(mat[ind[g - 1]:ind[g], ], rowvar = False) for\n",
        "                     g in range(1, G + 1)]\n",
        "                w = np.sum(w, axis = 0)\n",
        "                r = r[np.abs(r - w[0, 1]).argmin()]  # choose r that is w[0,1]\n",
        "\n",
        "            S[i, j] = S[j, i] = r\n",
        "    return [mus, S]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbFXSh5VR_Ab"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "\n",
        "def generate_nan(X, non_missing , missing_rate):\n",
        "    X_copy=np.copy(X)\n",
        "\n",
        "    X_non_missing_col = X_copy[:, non_missing]\n",
        "    X1_missing = X_copy[:, [i for i in range(X.shape[1]) if i not in non_missing]]\n",
        "\n",
        "    X_non_missing_row = X1_missing[non_missing]\n",
        "    X_missing = X1_missing[len(non_missing):(X.shape[0]+1)]\n",
        "\n",
        "    XmShape = X_missing.shape\n",
        "    na_id = np.random.randint(0, X_missing.size, round(missing_rate * X_missing.size))\n",
        "    X_nan = X_missing.flatten()\n",
        "    X_nan[na_id] = np.nan\n",
        "    X_nan = X_nan.reshape(XmShape)\n",
        "\n",
        "    X1_nan = np.vstack((X_non_missing_row, X_nan))\n",
        "    X_nan = np.hstack((X_non_missing_col, X1_nan))\n",
        "    return X_nan\n",
        "\n",
        "def PHF(Xm, y, G):\n",
        "    p = Xm.shape[1]\n",
        "    non_missing_id = np.where(np.sum(np.isnan(Xm), axis = 0) == 0)\n",
        "    q = max(non_missing_id)[-1] + 1\n",
        "    # initialize the parameter with 0s\n",
        "    S = np.zeros((p, p))\n",
        "    # estimating the parameter for the fully observed features\n",
        "    mu = np.array([np.nanmean(Xm[y == g, :], axis = 0) for g in range(G)]).T  # the mean is stored column\n",
        "    S[:q, :q] = sum([sum(y == g) * np.cov(Xm[y == g, :q], rowvar = False, ddof = 0) for g in range(G)]) / len(y)\n",
        "    # estimating the parameter in step 2 of the algorithm:\n",
        "    for j in range(q, p):\n",
        "        id = ~np.isnan(Xm[:, j])\n",
        "        Xfj = Xm[id, :][:, np.hstack((range(q), j))]\n",
        "        yfj = y[id]\n",
        "        covm = sum([sum(yfj == g) * np.cov(Xfj[yfj == g, :], rowvar = False, ddof = 0) for g in range(G)]) / len(yfj)\n",
        "        Q = covm[-1, range(q)]  # row vector\n",
        "        P = np.matmul(Q, np.linalg.inv(covm[:q, :q]))\n",
        "        S[j, range(q)] = np.matmul(P, S[:q, :q])\n",
        "\n",
        "        Xj, yj = Xm[id, j], y[id]\n",
        "        cal_S = lambda g: np.dot(Xj[yj == g] - mu[j, g], Xj[yj == g] - mu[j, g])\n",
        "        S[j, j] = sum(map(cal_S, range(G)))/len(yj)\n",
        "\n",
        "        S[j, range(q, j)] = np.array([dper_sigij(Xm, y, G, mu, i, j, S[i, i], S[j, j]) for i in range(q, j)]).flatten()\n",
        "        S[:, j] = S[j, :].T\n",
        "    return mu, S\n",
        "\n",
        "\n",
        "def dper_sigij(X, y, G, mus, i, j, sigii, sigjj):\n",
        "    \"\"\"\n",
        "    X: input, should be a numpy array\n",
        "    y: label\n",
        "    G: number of classes\n",
        "    i, j: index of the column\n",
        "    sigii: sigma_ii\n",
        "    sigjj: sigma_jj\n",
        "    \"\"\"\n",
        "    epsilon = 1e-5  # define epsilon to put r down to 0 if r < epsilon\n",
        "\n",
        "    mat = X[:, [i, j]]\n",
        "\n",
        "    # drop rows with NA\n",
        "    idx = ~np.isnan(mat).any(axis = 1)\n",
        "    mat, y_arr = mat[idx], y[idx]\n",
        "\n",
        "    A = len(y_arr)\n",
        "    scaled_mat = [mat[y_arr == g, :] - mus[[i, j], g] for g in range(G)]\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 0])\n",
        "    s11 = sum(map(q, range(G)))\n",
        "    q = lambda g: np.dot(scaled_mat[g][:, 1], scaled_mat[g][:, 1])\n",
        "    s22 = sum(map(q, range(G)))\n",
        "    d = lambda g: np.dot(scaled_mat[g][:, 0], scaled_mat[g][:, 1])\n",
        "    s12 = sum(map(d, range(G)))\n",
        "    B = sigii * sigjj * A - s22 * sigii - s11 * sigjj\n",
        "    coefficient = [-A, s12, B, s12 * sigii * sigjj]\n",
        "    r = np.roots(coefficient)\n",
        "\n",
        "    r = r[abs(np.imag(r)) < epsilon]\n",
        "    r = np.real(r)\n",
        "    r[abs(r) < epsilon] = 0\n",
        "\n",
        "    if len(r) > 1:\n",
        "        condi_var = sigjj - r ** 2 / sigii\n",
        "        # print('condi_var',condi_var)\n",
        "        eta = -A * np.log(condi_var) - (sigjj - 2 * r / sigii * s12 +\n",
        "                                        r ** 2 / sigii ** 2 * s11) / condi_var\n",
        "        # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "        #  therefore, we drop NA elements of eta\n",
        "        r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "    if len(r) > 1:\n",
        "        r = r[np.abs(r - s12 / A).argmin()]  # select r that is closet to w[0,1]\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def PHF1Cl(Xm):\n",
        "  p = Xm.shape[1]\n",
        "  non_missing_id = np.where(np.sum(np.isnan(Xm), axis=0)==0)\n",
        "  q = max(non_missing_id)[-1] + 1\n",
        "  # initialize the parameter with 0s\n",
        "  mu = np.zeros((p, 1))\n",
        "  S = np.zeros((p,p))\n",
        "  # estimating the parameter for the fully observed features\n",
        "  mu[:q,:] = np.mean(Xm[:,:q], axis = 0).reshape((-1,1)) # the mean is stored column\n",
        "  S[:q,:q] =   np.cov(Xm[:, :q], rowvar = False, ddof = 0)\n",
        "  # estimating the parameter in step 2 of the algorithm:\n",
        "  for j in range(q,p):\n",
        "    id = ~np.isnan(Xm[:,j])\n",
        "    Xfj = Xm[id,:][:,np.hstack((range(q),j))]\n",
        "    covm = np.cov(Xfj, rowvar = False, ddof = 0)\n",
        "    Q = covm[-1,range(q)] #row vector\n",
        "    P = np.matmul(Q, np.linalg.inv(covm[:q,:q]))\n",
        "    S[j,range(q)]  = np.matmul(P, S[:q,:q])\n",
        "\n",
        "    idj = ~np.isnan(Xm[:,j])\n",
        "    Xj = Xm[idj,j]\n",
        "    mu[j,:] =  np.nanmean(Xm[:,j], axis = 0)\n",
        "    S[j,j] = sum((Xj - mu[j])**2) /len(Xj)\n",
        "\n",
        "    S[j, range(q,j)] = np.array([dper_sigij1Cl(Xm, mu, i,j, S[i,i], S[j,j]) for i in range(q,j)]).flatten()\n",
        "    S[:,j] = S[j, :].T\n",
        "  return mu, S\n",
        "\n",
        "def dper_sigij1Cl(X, mus, i,j, sigii, sigjj):\n",
        "        '''\n",
        "        X: input, should be a numpy array\n",
        "        y: label\n",
        "        G: number of classes\n",
        "        i, j: index of the column\n",
        "        sigii: sigma_ii\n",
        "        sigjj: sigma_jj\n",
        "        '''\n",
        "        epsilon = 1e-5 # define epsilon to put r down to 0 if r < epsilon\n",
        "        n,p = X.shape[0], X.shape[1]\n",
        "\n",
        "        mat = X[:,[i,j]]\n",
        "\n",
        "        # drop rows with NA\n",
        "        idx = ~np.isnan(mat).any(axis=1)\n",
        "        mat = mat[idx]\n",
        "\n",
        "        A = len(mat)\n",
        "        scaled_mat = mat-mus[[i,j]].T\n",
        "        scaled_mat = np.vstack(scaled_mat)\n",
        "        s11 = sum(scaled_mat[:,0]**2)\n",
        "        s22 = sum(scaled_mat[:,1]**2)\n",
        "        s12 = sum(scaled_mat[:,0]*scaled_mat[:,1])\n",
        "\n",
        "        B = sigii*sigjj*A - s22 * sigii - s11 * sigjj\n",
        "        coefficient = [-A, s12, B, s12*sigii*sigjj]\n",
        "        r = np.roots(coefficient)\n",
        "\n",
        "        r = r[abs(np.imag(r)) < epsilon]\n",
        "        r = np.real(r)\n",
        "        r[abs(r) < epsilon] = 0\n",
        "\n",
        "        if len(r)>1:\n",
        "          condi_var = sigjj - r**2/sigii\n",
        "          # print('condi_var',condi_var)\n",
        "          eta = -A*np.log(condi_var)-(sigjj-2*r/sigii*s12 +\n",
        "                                      r**2/sigii**2*s11)/condi_var\n",
        "          # if condi_var <0 then eta = NA. in practice, it's impossible for cov to be negative\n",
        "          #  therefore, we drop NA elements of eta\n",
        "          r = r[eta == max(eta[~np.isnan(eta)])]\n",
        "\n",
        "        if len(r) > 1:\n",
        "            r = r[np.abs(r-s12/A).argmin()] # select r that is closet to w[0,1]\n",
        "\n",
        "        return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnXPL5TYjN1Q"
      },
      "outputs": [],
      "source": [
        "def l2err_inv(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return norm(inv(Strue)-inv(S))/(p*p)\n",
        "\n",
        "def l2err(Strue, S):\n",
        "    p = S.shape[0]\n",
        "    return norm((Strue)-(S)) / (p*p)\n",
        "\n",
        "def normalize_data(X):\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X)\n",
        "  return scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad3jJgOfdqkH"
      },
      "outputs": [],
      "source": [
        "def experiment(X,y, n, missing_rate):\n",
        "    G = len(np.unique(y))\n",
        "    S0=np.cov(X.T)\n",
        "    #print(S0.shape)\n",
        "    err = []\n",
        "    i_err=[]\n",
        "    for i in range(n):\n",
        "        mu_0=np.array([np.mean(X[y==g,:])  for g in np.unique(y) ]).T\n",
        "        Xm0 = generate_nan(X, [0,1], missing_rate)\n",
        "        Xm=Xm0\n",
        "        muPhf, SPhf = PHF(Xm, y, G)\n",
        "\n",
        "        muDper, SDper = dper(Xm, y, G)\n",
        "\n",
        "        XMice= IterativeImputer(max_iter=100).fit(Xm).transform(Xm)\n",
        "        SMice =  sum([sum(y==g)*np.cov(XMice[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        Xm_copy= pd.DataFrame.from_records(Xm)\n",
        "        Missf= MissForest()\n",
        "        XMissf_df = Missf.fit_transform(Xm_copy)\n",
        "        XMissf= XMissf_df.to_numpy()\n",
        "        SMissf =  sum([sum(y==g)*np.cov(XMissf[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        XSoft =  SoftImpute(max_iters = 100, verbose = False).fit_transform(Xm)\n",
        "        SSoft =  sum([sum(y==g)*np.cov(XSoft[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "#       Xxgb = XGBImputer().fit_transform(Xm)\n",
        "#       Sxgb = sum([sum(y==g)*np.cov(Xxgb[y==g, :], rowvar = False) for g in range(G)])/len(y)\n",
        "\n",
        "        i_err.append(np.array([l2err_inv(S0, SPhf), l2err_inv(S0, SDper),\n",
        "                             l2err_inv(S0, SMice), l2err_inv(S0, SMissf),\n",
        "                             l2err_inv(S0, SSoft)]))\n",
        "\n",
        "        err.append(np.array([l2err(S0, SPhf), l2err(S0, SDper),\n",
        "                             l2err(S0, SMice), l2err(S0, SMissf),\n",
        "                             l2err(S0, SSoft)]))\n",
        "    return i_err, err"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIalcQEib0Um"
      },
      "source": [
        "## Experiment on dataset 5: Thyroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu3tX1qpb5EG",
        "outputId": "6e450683-6de8-458f-a1e9-c31ee61d16ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "35\n",
            "30\n",
            "(215, 5)\n",
            "2.989\n",
            "5.031\n",
            "0.187\n",
            "5.336\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/new-thyroid.data',\n",
        "                  sep = \",\", header = None)\n",
        "data.head()\n",
        "\n",
        "data = data.to_numpy()\n",
        "X,y = data[:, [x for x in range(data.shape[1]) if x != 0]].astype(np.float32),data[:,0]\n",
        "G = len(np.unique(y))\n",
        "le2 = LabelEncoder()\n",
        "y = le2.fit_transform(y)\n",
        "for g in range(G):\n",
        "  print(sum(y==g))\n",
        "print(X.shape)\n",
        "X = normalize_data(X)\n",
        "S = np.cov(X,rowvar = False)\n",
        "print(norm(S).round(3))\n",
        "print(norm(inv(S)).round(3))\n",
        "print(np.linalg.det(S).round(3))\n",
        "print(np.linalg.det(inv(S)).round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V56fS8yEb8uA",
        "outputId": "98686e35-e6ae-4984-9079-3e7d96bc21d6"
      },
      "outputs": [],
      "source": [
        "num = 10\n",
        "e_inv20,e20 = experiment(X,y,num, missing_rate=.2)\n",
        "e_inv40,e40 = experiment(X,y,num, missing_rate=.4)\n",
        "e_inv60,e60 = experiment(X,y,num, missing_rate=.6)\n",
        "e_inv80,e80 = experiment(X,y,num, missing_rate=.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSnsLxFjb9BI",
        "outputId": "b0150a21-0552-464a-beae-a4ffa812a19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.083, 0.083, 0.081, 0.084, 0.083],\n",
              "       [0.083, 0.083, 0.084, 0.085, 0.086],\n",
              "       [0.086, 0.086, 0.083, 0.09 , 0.089],\n",
              "       [0.085, 0.085, 0.088, 0.093, 0.091]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e20, axis = 0), np.mean(e40, axis = 0),\n",
        "          np.mean(e60, axis = 0),np.mean(e80, axis = 0))).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx_btShJb9EK",
        "outputId": "40a9468c-236c-4f2d-dbd9-b573df967b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.002, 0.002, 0.002, 0.002, 0.002],\n",
              "       [0.003, 0.003, 0.002, 0.002, 0.002],\n",
              "       [0.005, 0.004, 0.003, 0.003, 0.003],\n",
              "       [0.005, 0.005, 0.01 , 0.004, 0.004]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e20, axis = 0), np.std(e40, axis = 0),\n",
        "          np.std(e60, axis = 0),np.std(e80, axis = 0))).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-nWCf8ob9On",
        "outputId": "ef330059-dfc0-4970-fa72-a4d56f25d5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inv err of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.093, 0.093, 0.105, 0.094, 0.094],\n",
              "       [0.105, 0.104, 0.37 , 0.105, 0.117],\n",
              "       [0.148, 0.143, 1.254, 0.135, 0.182],\n",
              "       [0.309, 0.302, 7.601, 0.211, 0.326]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('inv err of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.mean(e_inv20, axis = 0), np.mean(e_inv40, axis = 0),\n",
        "          np.mean(e_inv60, axis = 0),np.mean(e_inv80, axis = 0))).round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMx-aymnb9YC",
        "outputId": "52c32237-73d5-4cd1-8e76-1406e7f37d69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inv std of PHF, DPER, Mice, MissForest, Soft-Impute\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[5.000e-03, 4.000e-03, 1.900e-02, 7.000e-03, 8.000e-03],\n",
              "       [1.600e-02, 1.500e-02, 2.480e-01, 1.600e-02, 2.000e-02],\n",
              "       [4.300e-02, 4.200e-02, 6.440e-01, 3.200e-02, 5.200e-02],\n",
              "       [2.740e-01, 2.600e-01, 1.032e+01, 1.840e-01, 2.500e-01]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('inv std of PHF, DPER, Mice, MissForest, Soft-Impute')\n",
        "np.vstack((np.std(e_inv20, axis = 0), np.std(e_inv40, axis = 0),\n",
        "          np.std(e_inv60, axis = 0),np.std(e_inv80,axis = 0))).round(3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "01Q1wGI3uIdg",
        "LIalcQEib0Um"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
